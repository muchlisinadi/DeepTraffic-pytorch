{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fad799e-6269-4b33-ac31-c398fc53332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from datasets.encrypted import Encrypted2ClassSessionAllLayers, Encrypted2ClassSessionL7, Encrypted2ClassFlowL7\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from models.cnn import LitCNN\n",
    "from models.lstm import LitRNN\n",
    "from models.mlp import LitMLP\n",
    "from models.svm import LitSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f9e5e-1be3-4739-a52b-1b1f123162f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/echowei/DeepTraffic/master/2.encrypted_traffic_classification/3.PerprocessResults/2class.zip to data/EncryptedTraffic/raw/2class.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3437909eb5fe45e5aeeeffeb63838ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23454719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/EncryptedTraffic/raw/2class.zip to data/EncryptedTraffic/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: results/Encrypted2ClassSessionAllLayers/CNN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Encrypted2ClassSessionAllLayers - CNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name         | Type      | Params\n",
      "--------------------------------------------\n",
      "0  | train_acc    | Accuracy  | 0     \n",
      "1  | train_f1     | F1Score   | 0     \n",
      "2  | train_pmacro | Precision | 0     \n",
      "3  | train_pmicro | Precision | 0     \n",
      "4  | train_rmacro | Recall    | 0     \n",
      "5  | train_rmicro | Recall    | 0     \n",
      "6  | val_acc      | Accuracy  | 0     \n",
      "7  | val_f1       | F1Score   | 0     \n",
      "8  | val_pmacro   | Precision | 0     \n",
      "9  | val_pmicro   | Precision | 0     \n",
      "10 | val_rmacro   | Recall    | 0     \n",
      "11 | val_rmicro   | Recall    | 0     \n",
      "12 | net          | CNN       | 21.4 K\n",
      "--------------------------------------------\n",
      "21.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.4 K    Total params\n",
      "0.043     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muchlisinadi/anaconda3/envs/deeptraffic/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:495: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/muchlisinadi/anaconda3/envs/deeptraffic/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/muchlisinadi/Documents/Project/personal_develop/Deep-Traffic-Utils/models/cnn.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "/home/muchlisinadi/anaconda3/envs/deeptraffic/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/muchlisinadi/anaconda3/envs/deeptraffic/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (18) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c445d387a14193abba4d90d03b6e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_dir = \"data\"\n",
    "log_dir = Path(\"results\")\n",
    "BATCH_SIZE = 250*4\n",
    "N_EPOCH = 50\n",
    "\n",
    "\n",
    "for Dataset in [Encrypted2ClassSessionAllLayers, Encrypted2ClassSessionL7, Encrypted2ClassFlowL7]:\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    train_data = Dataset(root=download_dir, download=True, train=True, transform=transform)\n",
    "    test_data = Dataset(root=download_dir, download=True, train=False, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n",
    "    test_loader = DataLoader(test_data, batch_size=10000, shuffle=True, num_workers=2)\n",
    "    \n",
    "    dataset_name = train_data.__class__.__name__\n",
    "    dataset_classes = train_data.classes\n",
    "    \n",
    "    for Model in [LitCNN, LitRNN, LitMLP, LitSVM]:\n",
    "        model = Model(num_classes=len(dataset_classes))\n",
    "        model_name = model.net.__class__.__name__\n",
    "        logger = TensorBoardLogger(log_dir, name=f\"{dataset_name}/{model_name}\")\n",
    "        early_stopping = EarlyStopping('val_loss', mode=\"min\")\n",
    "        trainer = pl.Trainer(gpus=1, max_epochs=N_EPOCH, precision=16, limit_train_batches=0.5, logger=logger, callbacks=[early_stopping])\n",
    "        print(f\"Train {dataset_name} - {model_name}\")\n",
    "        trainer.fit(model, train_loader, test_loader)\n",
    "        \n",
    "        # Free memory\n",
    "        del model\n",
    "        del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe876f-b759-47c6-886e-92ffeeadca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = \"data\"\n",
    "log_dir = Path(\"results\")\n",
    "BATCH_SIZE = 250*4\n",
    "N_EPOCH = 50\n",
    "\n",
    "from datasets.encrypted import Encrypted12ClassSessionAllLayers, Encrypted12ClassSessionL7, Encrypted12ClassFlowL7\n",
    "\n",
    "\n",
    "for Dataset in [Encrypted12ClassSessionAllLayers, Encrypted12ClassSessionL7, Encrypted12ClassFlowL7]:\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    train_data = Dataset(root=download_dir, download=True, train=True, transform=transform)\n",
    "    test_data = Dataset(root=download_dir, download=True, train=False, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n",
    "    test_loader = DataLoader(test_data, batch_size=10000, shuffle=True, num_workers=2)\n",
    "    \n",
    "    dataset_name = train_data.__class__.__name__\n",
    "    dataset_classes = train_data.classes\n",
    "    \n",
    "    for Model in [LitCNN, LitRNN, LitMLP, LitSVM]:\n",
    "        model = Model(num_classes=len(dataset_classes))\n",
    "        model_name = model.net.__class__.__name__\n",
    "        logger = TensorBoardLogger(log_dir, name=f\"{dataset_name}/{model_name}\")\n",
    "        early_stopping = EarlyStopping('val_loss', mode=\"min\")\n",
    "        trainer = pl.Trainer(gpus=1, max_epochs=N_EPOCH, precision=16, limit_train_batches=0.5, logger=logger, callbacks=[early_stopping])\n",
    "        print(f\"Train {dataset_name} - {model_name}\")\n",
    "        trainer.fit(model, train_loader, test_loader)\n",
    "        \n",
    "        # Free memory\n",
    "        del model\n",
    "        del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd3c454-4b76-4f41-ad4a-4364e646b9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepTraffic",
   "language": "python",
   "name": "deeptraffic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
